---
title: "stoner"
author: "Wes Hinsley"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
## Introduction

`stoner` is a package to help with a common administrative task for Montagu: creation or development of a touchstone. A touchstone
links together the coverage, demography, responsibilities and outputs for a particularly set of runs that VIMC modellers are asked
to perform. Once a touchstone is opened, it is designed to be fixed, so having downloaded input data from a particular touchstone,
if a modelling group chooses to download the input data again, they will always get the same result. This ensures reproducibility,
but as a side effect, it means that if there is even a minor error that we discover in a touchstone, we will open a new version
of that touchstone, so that any results made using the erroneous touchstone are still well audited and reproducible.

This comes at a cost of creating new touchstones, or new versions quite often, including a significant period of development
to create the touchstone, and more repetitive adjustments. Historically, this has been difficult to review, since the code to
perform CSV reading and SQL updates has often been tangled. [dettl](https://github.com/vimc/dettl) helps here to encourage
separation of such imports into cleanly bounded extract, transform and load stages, with unit testing of each stage; this is
our state of the art we use for the [montagu-imports](https://github.com/vimc/montagu-imports) repository. This
clarifies things greatly, but at times, at the cost of brevity, where writing a single SQL query in the three stages with tests can
feel somewhat strenuous, compared to the simplicity of the actual task.

`stoner` is in principle very similar to a [dettl](https://github.com/vimc/dettl) import; it has extract, transform and load
phases, and tests on the extract and transform phases. It is specifically designed for a particular set of tasks, and relying
on specific metadata, in order to do the specific tasks of incrementally building a touchstone. The aim is that the montagu-import
for creating a new touchstone (or making edits to a touchstone that is in preparation), will consist of single-line functions for
extract, transform and load, which stoner will take care of. The tests in the import will consist of a single-line call to stoner's
tests, followed by tests that are specific to the metadata in the import.

The review of a montagu-import that uses stoner, will therefore be a case of reviewing the metadata, and the meta-data-specific
tests; and all of the reproducible work will have been separately reviewed in the stoner package. Tests of `stoner` itself are 
done by running a docker instance of the montagu database, and a rack of tests for each element of an import exist in 
`tests/testthat/examples`. These tests are designed to mimic as closely as possible the shape of a montagu-import.


## Creating a montagu-import that uses stoner

## What stoner does

### stone_extract

The extract phase is called as `stoner::stone_extract(path, con)`; the arguments are the path to the particular montagu-import, and a
database connection. Internally, `stoner` splits the extract phase into two; the first reads all the `csv` metadata first, and
the second queries the database for rows regarding the metadata. This split is necessary because (for example) there are several 
different parts of the import that might all refer to touchstones, and it would be good to know about all the touchstones we ever 
mention in the metadata, at the point where we query the `touchstone` database table.

The metadata files are expected to be in a folder called `meta`, within the import.

#### touchstone and touchstone_name

  * In the `extract-csv` phase, read `touchstone_name` and `touchstone` csv files, if they exist.
  * In the `extract-db` phase, fetch `touchstone` rows from database for any matching `id` in `touchstone_csv`, 
    and `touchstone_name` rows from database for any matching `id` in `touchstone_name_csv`, and
    also matching `touchstone_name` in `touchstone_csv`.
  * The format of all new `touchstone.id` should be `touchstone_name-version`
  * All new `touchstone.description` should be `touchstone_name (version v)`
  * All new `touchstone.status` must be either `in-preparation`, `open`, or `finished`.

#### scenario_description

  * In the `extract-csv` phase, read `meta/scenario_description.csv` if it exists.
  * In the `extract-db` phase, read all matching rows from the scenario_description table.
  * Also lookup Montagu's `disease` table for ids that match `scenario_description_csv`$disease.

#### touchstone_demographic_dataset

  * In the `extract-csv` phase, read `meta/touchstone_demographic_dataset.csv` if it exists. 
    This csv is pleasantly human readable - it uses string references instead of database ids. 
    It therefore differs from how the `touchstone_demographic_dataset` table appears in the 
    database, and we will need to extract more metadata to transform the strings into ids.
  * Slightly out of place, but the extract code will all fail here untidily, if the columns are
    incorrect. So a set of tidy tests is done here, to check the CSV columns and their types.
  * In the `extract-db` phase, find any existing `touchstone_demographic_datasets` that refer to
    touchstones that the CSV mentions.
  * Also look up `demographic_source`, `demographic_statistic_type` and `touchstone` information
    for any rows in the CSV.
  * Lookup the `demographic_datasets` that refer to the above sources and types.
  * For convenience, we do some mashes here for quickly comparing `(touchstone, source, type)`
    triples for touchstone_demographic_datasets, and `(source, type`) pairs for `demographic dataset`.

### stone_test_extract

#### touchstone and touchstone_name

  * Check that columns in the `touchstone` and `touchstone_name` csv files match the databse table.
  * All `touchstone.touchstone_name` must have a matching entry in either the `touchstone_name` csv file, or the
    `touchstone_name` database table.
  * All `touchstone.touchstone_name` and `touchstone.id` must be unique within the csv files.

#### scenario_description

  * Test that all diseases in `scenario_description_csv`$disease are valid.
  * Test that there are no rows in `scenario_description_csv` with duplicate ids.

#### touchstone_demographic_dataset
  * Check that all the `demographic_source` and `demographic_statistic_type` entries in the CSV file
    exist in the database. We don't create these in stoner; a demographic import must do that.
  * Check that for each `(demographic_source, demographic_statistic_type)` pair in the CSV file, a
    `demographic_dataset` already exists linking the two. Again, we don't create those (currently) in stoner.
  * Check that all the touchstones referred to in the CSV file exist - either in the database, or in
    the `touchstone.csv` file extracted. (`touchstone.id` is a string, so we do not need to worry about
    database serial numbers here).
  * Check there are no duplicate `(Touchstone, demographic_dataset)` pairs in the CSV.

### stone_transform

The transform stage involves processing the `extracted_data` and returning a list of data.frames
that are have the right names, and correct columns to be appended to tables in the Montagu database.
During the transform, some tables will have an extra column `already_exists_db` added, to indicate
that the entire row matches exactly with one in the database. At the end of the transform, any rows
that have this column set will be dropped if the rows are exactly the same
as the database content, or kept for potential editing, which we'll discuss in the load section.
Call the transform code with `stoner::stone_transform(extracted_data)` from within the dettl
transform.

#### touchstone and touchstone_name

Having noted whether any of the rows in `touchstone_csv` and `touchstone_name_csv` are entirely
new, or have matching ids but differ in some other column to the database:

  * Use new/differing rows in `touchstone_csv` as the transformed `touchstone` table rows.
  * Use new/differing rows in `touchstone_name_csv` as the transformed `touchstone_name` table.

#### scenario_description

  * Use new/differing rows in `scenario_description_csv` as the transformed `scenario_description` table rows.

#### touchstone_demographic_dataset

  * Work out the `demographic_dataset` id for each new `touchstone_demographic_dataset` by comparing
    the mashes created in the extract stage. Ignore any `(touchstone, demographic_dataset)` pairs that
    already exactly exist in the db.
  * For the remaining rows, some may match a `demographic_statistic_type`, but not a `demographic_source`
    in that touchstone. For example, sometimes we have fixed an issue and put the result in a new
    version of the `demographic_source`. For these rows, copy the `id` from the existing row for that 
    `demographic_statistic_type` - since there is only ever one instance of each `demographic_statistic_type`
    in a touchstone. We will want to update these rows in the load stage.
  * Assign negative, and decrementing ids to each row for which no existing `demographic_statistic_type` 
    matched the row for that touchstone. These are the new rows to be added.

### stone_test_transform

`stoner::stone_test_transform(transformed_data)` should be called from test_transform.R in the montagu-import.

#### touchstone and touchstone_name

  * Test that in `touchstone`, `id` is in the format `touchstone_name`-`version`
  * Test that all touchstones have valid status. (open, in-preparation, finished)

#### scenario_description

  * Nothing further to test here; all useful tests are in the extract stage.

#### touchstone_demographic_dataset

  * Nothing further to test here; all useful tests are in the extract stage.
 
### stone_load

The montagu-import using stoner must use a custom load, not an automatic one, since the first line of the
load should be `stoner::stone_load(transformed_data, con)`.

#### touchstone_name

  * `touchstone_name` is uploaded first, since `touchstone` may refer to it.
  * Rows with new ids are trivially appended.
  * Rows with the same id but differing other columns will be edited in-place, provided that
    if any touchstone refers to the touchstone_name id, that touchstone must have status `in-preparation`.

#### touchstone

  * Rows with new ids are trivially appended.
  * Rows with the same id but differing other columns will be edited in-place, provided that
    the status of that touchstone is `in-preparation`.

#### scenario_description

  * Scenario descriptions with new ids are appended.
  * Existing ids are edited if every touchstone that refers to that `scenario_description` is in the
    `in-preparation` stage. However, we do want to improve scenario_descriptions (without changing
    their meaning, or any data connected to them), or touchstones that are more recent. See the
    Advanced Use section later.

#### touchstone_demographic_dataset

  * For all `touchstone_demographic_dataset` rows with a negative `id`, append the rows to the table,
    preserving lookup information from the negative id, to the positive one that the database
    assigns to each new row.
    
  * Where `id` was positive (and therefore already existing in the db table), check whether the 
    `touchstone` for that row in the proposed `touchstone_demographic_dataset` is of status 
    `in-preparation`. If not, then abort. If it is, then update the `demographic_dataset` for 
    that `(id, touchstone)` entry to the new value.

### (test_load)

There are no generic tests for load; these must be implemented specifically for the metadata
in the montagu-import.

## Advanced Use

### Overwriting scenario_description

The `scenario_description` table provides human-readable scenario information for the ids. Scenarios,
however, are shared between touchstones. On occasion, it has been desirable to update the human-readable
descriptions to make them more clear for a particular scenario, thus changing the way the text appears,
for both future and historic touchstones.

Usually, this would not be permitted, but since this is purely for the purpose of readability and clarity,
and because it causes no data changes, the default behaviour of forbidding such changes on open or finished
touchstones can be relaxed by using this longer form of `stoner::load` :-

`stoner::stone_load(transformed_data, con, allow_overwrite_scenario_description = TRUE)`
