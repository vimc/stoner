---
title: "stoner"
author: "Wes Hinsley"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
## Introduction

`stoner` is a package to help with a common administrative task for Montagu: creation or development of a touchstone. A touchstone
links together the coverage, demography, responsibilities and outputs for a particularly set of runs that VIMC modellers are asked
to perform. Once a touchstone is opened, it is designed to be fixed, so having downloaded input data from a particular touchstone,
if a modelling group chooses to download the input data again, they will always get the same result. This ensures reproducibility,
but as a side effect, it means that if there is even a minor error that we discover in a touchstone, we will open a new version 
of that touchstone, so that any results made using the erroneous touchstone are still well audited and reproducible.

This comes at a cost of creating new touchstones, or new versions quite often, including a significant period of development
to create the touchstone, and more repetitive adjustments. Historically, this has been difficult to review, since the code to
perform CSV reading and SQL updates has often been tangled. [dettl](https://github.com/vimc/dettl) helps here to encourage
separation of such imports into cleanly bounded extract, transform and load stages, with unit testing of each stage; this is
our state of the art we use for the [montagu-imports](https://github.com/vimc/montagu-imports) repository. This
clarifies things greatly, but at times, at the cost of brevity, where writing a single SQL query in the three stages with tests can
feel somewhat strenuous, compared to the simplicity of the actual task. 

`stoner` is in principle very similar to a [dettl](https://github.com/vimc/dettl) import; it has extract, transform and load
phases, and tests on the extract and load phases. But it is specifically designed for a particular set of tasks, and relying 
on specific metadata, in order to do the specific tasks of incrementally building a touchstone. The aim is that the montagu-import 
for creating a new touchstone (or making edits to a touchstone that is in preparation), will consist of single-line functions for 
extract, transform and load, which stoner will take care of. The tests in the import will consist of a single-line call to stoner's 
tests, followed by tests that are specific to the metadata in the import.

The review of a montagu-import that uses stoner, will therefore be a case of looking at the metadata, and the tests that are
specific to the metadata, and all of the reproducible work will be separately reviewed, once for all, in the stoner package.

## Creating a montagu-import that uses stoner

## What stoner does

### extract

The extract phase is called as `stoner::extract(path, con)`; the arguments are the path to the particular montagu-import, and a
database connection. Within `path`, stoner expects a folder called `meta` to exist, containing the metadata for the import. 
Various CSV files are expected to be read from there, as part of the extraction. and stoner will then query the database to 
find table data, in order to distinguish between existing rows (perhaps to be edited) and new rows to be added.

#### touchstone and touchstone_name

  * If present within `path`, read `meta/touchstone.csv` as `touchstone_csv`.
  * If present within `path`, read `meta/touchstone_name.csv` as `touchstone_name_csv`.
  * Fetch `touchstone` rows from database for any matching `id` in `touchstone_csv`.
  * Fetch `touchstone_name` rows from database for any matching `id` in `touchstone_name_csv`, and
    also matching `touchstone_name` in `touchstone_csv`.

#### scenario_description

  * If present within `path`, read `meta/scenario_description.csv` as `scenario_description_csv`.
  * Fetch `scenario_description` rows from database for any matching `id` in `scenario_description_csv`.
  * Also lookup Montagu's `disease` table for ids that match `scenario_description_csv`$disease.

#### touchstone_demographic_dataset

  * Load the CSV, and query the database for all the demographic_datasets in touchstones that
    are reported in the CSV.
  * Lookup the next serial id for new entries in the touchstone_demographic_dataset table.
  * Lookup `demographic_statistic_type` and `demographic_source` information for all
    demographic datasets referred to.

### test-extract

Tests are carried out for each part of the touchstone, as follows. All items 
referred to will be in the `extracted_data` list, unless otherwise specified.

#### touchstone and touchstone_name

  * `touchstone` and `touchstone_csv` must be either both present, or both absent.
  * `touchstone_name` and `touchstone_name_csv` must be either both present, or both absent.
  * If they are present, then both files must columns matching the \code{touchstone} database table.
  * All `touchstone_csv`$`touchstone_name` values must match a `touchstone_name_csv`$`id`.

#### scenario_description

  * Test that all diseases in `scenario_description_csv`$disease are valid.
  * Test that all descriptions are non-empty. (Cannot check for duplicates here, since duplicates
    are permitted in the table; "No vaccination" is duplicated for all diseases.)

#### touchstone_demographic_dataset

  * Test for correct columns in the incoming CSV.
  * Expect that the `touchstone`, `demographic_source` and `demographic_statistic_type` in the CSVS
    will be strings, not numerical ids, and check that all strings are recognised in the appropriate
    tables
  * Check that for each `demographic_source` `demographic_statistic_type` pair in the CSV file, a
    `demographic_dataset` already exists linking the two.
  * Check there are no effective duplicate `(Touchstone, demographic_dataset)` pairs in the CSV.

### transform

The transform stage involves processing the `extracted_data` and returning a list of data.frames
that are have the right names, and correct columns to be appended to tables in the Montagu database.
During the transform, some tables will have an extra column `already_exists_db` added, to indicate 
that the entire row matches exactly with one in the database. At the end of the transform, any rows 
that have this column set will be dropped if the rows are exactly the same
as the database content, or kept for potential editing, which we'll discuss in the load section.

#### touchstone and touchstone_name

Having noted whether any of the rows in `touchstone_csv` and `touchstone_name_csv` are entirely
new, or have matching ids but differ in some other column to the database:

  * Use new/differing rows in `touchstone_csv` as the transformed `touchstone` table rows.
  * Use new/differing rows in `touchstone_name_csv` as the transformed `touchstone_name` table.

#### scenario_description

  * Use new/differing rows in `scenario_description_csv` as the transformed `scenario_description` table rows.

#### touchstone_demographic_dataset

  * Flag any entries in `touchstone_demographic_dataset_csv` that have an exact match of 
    (touchstone, demographic_dataset) in the database; these will be removed after the end of
    the transform stage.
  * Lookup existing `id` from the `touchstone_demographic_dataset` database table, for any
    exact matches.
  * For those that did not match, find the `id` of an existing row in `touchstone_demographic_dataset`
    whose `demographic_statistic_type` matches the row in question for that touchstone (in which case,
    the underlying `demographic_source` will differ). This handles the case where we fix a particular
    `demographic_statistic_type`, and put the new version in an updated `demographic_source`. So here,
    we use the old id, and attempt to update the `demographic_dataset` id in place.
  * If no existing `demographic_statistic_type` matched the row for that touchstone, then we appear
    to be adding a new demographic_dataset to the `touchstone_demographic_dataset`, so set the `id`
    to the `next_id` in the sequence

### test-transform

`stoner::test_transform(transformed_data)` should be called from test_transform.R in the montagu-import,
and it will perform the following standard tests on all transformed data - if they exist, since stoner
does not require them all to exist.

#### touchstone and touchstone_name
  
  * Test that in `touchstone`, `id` is in the format `touchstone_name`-`version`
  * Test that all touchstones have valid status. (open, in-preparation, finished)

#### scenario_description

All the useful tests are already done in the test_extract stage.

#### touchstone_demographic_dataset

  * Test that there is no duplicate `id` and no duplicate `demographic_dataset` in the final
    `touchstone_demographic_dataset` updates.

### load

The montagu-import using stoner msut use a custom load, not an automatic one, since the first line of the
load should be `stoner::load(transformed_data, con)`. 

#### touchstone_name
  
  * `touchstone_name` is uploaded first, since `touchstone` may refer to it. 
  * Rows with new ids are trivially appended.
  * Rows with the same id but differing other columns will be edited in-place, provided that 
    if any touchstone refers to the touchstone_name id, that touchstone must have status `in-preparation`.

#### touchstone

  * Rows with new ids are trivially appended.
  * Rows with the same id but differing other columns will be edited in-place, provided that 
    the status of that touchstone is `in-preparation`.

#### scenario_description

  * Scenario descriptions with new ids are appended.
  * Existing ids are edited if every touchstone that refers to that `scenario_description` is in the
    `in-preparation` stage. However, we do want to improve scenario_descriptions (without changing
    their meaning, or any data connected to them), or touchstones that are more recent. See the
    Advanced Use section later.

#### touchstone_demographic_dataset

  * For all `touchstone_demographic_dataset` rows with an `id` that doesn't match an existing `id` in
    the database table, append the rows to the table.
  * Where `id` is not in the table, check whether the `touchstone` for that row in the proposed
    `touchstone_demographic_dataset` is of status `in-preparation`. If not, then abort. If it is,
    then update the `demographic_dataset` for that `(id, touchstone)` entry to the new value.

### test-load

There are no generic tests for load; these must be implemented specifically for the metadata
in the montagu-import.

## Advanced Use

### Overwriting scenario_description

The `scenario_description` table provides human-readable scenario information for the ids. Scenarios,
however, are shared between touchstones. On occasion, it has been desirable to update the human-readable
descriptions to make them more clear for a particular scenario, thus changing the way the text appears,
for both future and historic touchstones.

Usually, this would not be permitted, but since this is purely for the purpose of readability and clarity,
and because it causes no data changes, the default behaviour of forbidding such changes on open or finished
touchstones can be relaxed by using this longer form of `stoner::load` :- 

`stoner::load(transformed_data, con, allow_overwrite_scenario_description = TRUE)`
